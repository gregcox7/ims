# Inference for comparing paired means {#inference-paired-means}

::: {.chapterintro}
In Chapter \@ref(inference-two-means) analysis was done to compare the average population value across two different groups.
Recall that one of the important conditions in doing a two-sample analysis is that the two groups are independent.
Here, independence across groups means that knowledge of the observations in one group doesn't change what we'd expect to happen in the other group.
But what happens if the groups are **dependent**?
Sometimes dependency is not something that can be addressed through a statistical method.
However, a particular dependency, **pairing** can be modeled quite effectively using many of the same tools we have already covered in this chapter.
:::

Paired data represent a particular type of experimental structure where the analysis is somewhat akin to a one-sample analysis (see Chapter \@ref(inference-one-mean)) but has other features that resemble a two-sample analysis (see Chapter \@ref(inference-two-means)).
As with a two-sample analysis, quantitative measurements are made on each of two different levels of the explanatory variable.
However, because the observational unit is **paired** across the two groups, the two measurements are subtracted such that only the difference is retained.
Table \@ref(tab:pairedexamples) presents some examples of studies where paired designs were implemented.

```{r pairedexamples}
temptbl <- tribble(
 ~variable,    ~col1, ~col2, ~col3, 
 "Car", "Smooth Turn vs Quick Spin", "amount of tire tread after 1,000 miles", "difference in tread",
 "Textbook", "UCLA vs Amazon", "price of new text", "difference in price",
 "Individual person", "Pre-course vs Post-course", "exam score", "difference in score"
)

temptbl %>%
 kable(caption = "Examples of studies where a paired design is used to measure the difference in the measurement over two conditions.",
    col.names = c("Observational unit", "Comparison groups", "Measurement", "Value of interest")) %>%
 kable_styling() 
```

::: {.important}
**Paired data.**

Two sets of observations are *paired* if each observation in one set has a special correspondence or connection with exactly one observation in the other data set.
:::

```{r include=FALSE}
terms_chp_21 <- c("paired data")
```

## Randomization test for $H_0: \mu_d = 0$

Consider an experiment done to measure whether tire brand Smooth Turn or tire brand Quick Spin has longer tread wear (in cm).
That is, after 1,000 miles on a car, which brand of tires has more tread, on average?

### Observed data {.unnumbered}

The observed data represent 25 tread measurements (in cm) taken on 25 tires of Smooth Turn and 25 tires of Quick Spin.
The study used a total of 25 cars, so on each car, one tire was of Smooth Turn and one was of Quick Spin.
Figure \@ref(fig:tiredata) presents the observed data, calculations on tread remaining (in cm).

The Smooth Turn manufacturer looks at the box plot and says:

> clearly the tread on Smooth Turn tires is higher, on average, than the tread on Quick Spin tires after 1,000 miles of driving.

The Quick Spin manufacturer is skeptical and retorts:

> but with only 25 cars, it seems that the variability in road conditions (sometimes one tire hits a pothole, etc.) could be what leads to the small difference in average tread amount.

```{r tiredata, fig.cap = "Boxplots of the tire tread data (in cm) and the brand of tire from which the original measurements came.", warning = FALSE, out.width = "90%"}

set.seed(47)
brandA <- rnorm(25, .310, .003)
brandB <- rnorm(25, .308, .003)
car <- c(paste("car ", 1:25))
miny <- min(brandA, brandB) - .003
maxy <- max(brandA, brandB) + .003

tires <- data.frame(tread = c(brandA, brandB), 
                    car = rep(car, 2), 
                    brand = c(rep("Smooth Turn", 25), rep("Quick Spin", 25)))

orig_means <- tires %>%
  mutate(`Tire Brand` = brand) %>%
  group_by(`Tire Brand`) %>%
  summarize(mean_tread = round(mean(tread),4))  %>%
  mutate(mean_label = c("bar(x)[QS]", "bar(x)[ST]")) %>%
  mutate(mean_label = paste(mean_label, " == ", mean_tread))

tires %>%
  mutate(`Tire Brand` = brand) %>%
ggplot(aes( x = `Tire Brand`, y = tread, color = `Tire Brand`)) +
  geom_boxplot(show.legend = FALSE, color = "black") +
  geom_text(aes(label = car), color = "grey", hjust = rep(c(-0.15, 1.3), each = 25),
            show.legend = FALSE, size = 2.5) +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  xlab("Brand of tire") +
  geom_point(show.legend = TRUE) +
  geom_text(data = orig_means, aes(label = mean_label, 
                y = 0.318), parse = TRUE, show.legend = FALSE) + 
  ggtitle("Original data")

```

We'd like to be able to systematically distinguish between what the Smooth Turn manufacturer sees in the plot and what the Quick Spin manufacturer sees in the plot.
Fortunately for us, we have an excellent way to simulate the natural variability (from road conditions, etc.) that can lead to tires being worn at different rates.

### Variability of the statistic {.unnumbered}

A randomization test will identify whether the differences seen in the box plot of the original data in Figure \@ref(fig:tiredata) could have happened just by chance variability.
As before, we will simulate the variability in the study under the assumption that the null hypothesis is true.
In this study, the null hypothesis is that average tire tread wear is the same across Smooth Turn and Quick Spin tires.

-   $H_0: \mu_{ST} = \mu_{QS},$ the average tread wear is the same for the two tire brands.\
-   $H_A: \mu_{ST} \ne \mu_{QS},$ the average tread wear is different across the two tire brands.

When observations are paired, the randomization process randomly assigns the tire brand to each of the observed tread values.
Note that in the randomization test for the two-sample mean setting (see Section \@ref(rand2mean)) the explanatory variable was **also** randomly assigned to the responses.
The change in the paired setting, however, is that the assignment happens *within* an observational unit (here, a car).
Remember, if the null hypothesis is true, it will not matter which brand is put on which tire because the overall tread wear will be the same across pairs.

Figures \@ref(fig:tiredata4) and \@ref(fig:tiredata5) show that the random assignment of group (tire brand) happens within a single car.
That is, every single car will still have one tire of each type.
It just so happens that the 4th car's tire brands were swapped and the 5th car's tire brands were not swapped.

```{r tiredata4, fig.cap = "The 4th car. The tire brand was randomly permuted, and in the randomization calculation, the measurements (in cm) ended up in different groups.", warning = FALSE, fig.asp = 0.50, out.width = "100%"}
# inches  about 1/32" per 3500 mi

theme_set(
  theme_bw() +
    theme(legend.position = "top", text = element_text(size = 6))
  )

origplot4 <- tires %>%
  mutate(`Tire Brand` = brand) %>%
  filter(car == "car  4") %>%
ggplot(aes( x = `Tire Brand`, y = tread, color = `Tire Brand`)) +
 # geom_boxplot() +
  geom_point() +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  xlab("Brand of tire") +
  ylim(c(miny, maxy)) + 
  geom_text(aes(label = car), color = "grey", hjust = rep(c(-0.15, 1.3), each = 1),
            show.legend = FALSE, size = 3) +
  ggtitle("Original data")

set.seed(47)
permdata <- tires %>%
  mutate(`Tire Brand` = brand) %>%
  group_by(car) %>%
  mutate(`Randomized Brand` = sample(brand))

shuffbrand4 <- permdata %>%
    filter(car == "car  4") %>%
ggplot(aes( x = `Tire Brand`, y = tread, color = `Randomized Brand`)) +
 # geom_boxplot() +
  geom_text(aes(label = car),color = "grey", hjust = rep(c(-0.15,1.3), each = 1),
            show.legend = FALSE, size = 3) +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  geom_point(show.legend = FALSE) +
  theme_void() + 
  ylim(c(miny, maxy)) + 
  theme(legend.position = "none", text = element_text(size = 6)) +
  ggtitle("Shuffled assignment of tire brand")

shuffbrandfull4 <- permdata %>%
    filter(car == "car  4") %>%
ggplot(aes( x = `Randomized Brand`, y = tread, color = `Randomized Brand`)) +
 # geom_boxplot() +
  geom_point() +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  xlab("Randomized brand of tire") +
  ylim(c(miny, maxy)) + 
  geom_text(aes(label = car), color = "grey",hjust = rep(c(-0.15,1.3), each = 1),
            show.legend = FALSE, size = 3) +
  ggtitle("Sorted data")

arrow <- ggplot(permdata, aes(x = 1, y = 1, xend = 2, yend = 1)) +
  geom_segment(lineend = "butt", linejoin = "mitre", size = 3,
               arrow = arrow(length = unit(0.1, "inches"))) +
  xlim(1,2) +
  theme_void()

origplot4 + shuffbrand4
```

```{r tiredata5, fig.cap = "The 5th car. The tire brand was randomly permuted to stay the same! In the randomization calculation, the measurements (in cm) ended up in the original groups.", warning = FALSE, fig.asp = 0.50, fig.height = 20, out.width = "100%"}

theme_set(
  theme_bw() +
    theme(legend.position = "top", text = element_text(size = 6))
  )

origplot5 <- tires %>%
  mutate(`Tire Brand` = brand) %>%
  filter(car == "car  5") %>%
ggplot(aes( x = `Tire Brand`, y = tread, color = `Tire Brand`)) +
 # geom_boxplot() +
  geom_point() +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  xlab("Brand of tire") +
  ylim(c(miny, maxy)) + 
  geom_text(aes(label = car), color = "grey",hjust = rep(c(-0.15, 1.3), each = 1),
            show.legend = FALSE, size = 3) +
  ggtitle("Original data")

shuffbrand5 <- permdata %>%
    filter(car == "car  5") %>%
ggplot(aes( x = `Tire Brand`, y = tread, color = `Randomized Brand`)) +
 # geom_boxplot() +
  geom_point(show.legend = FALSE) +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  theme_void() + 
  ylim(c(miny, maxy)) + 
  geom_text(aes(label = car), color = "grey",hjust = rep(c(-0.15,1.3), each = 1),
            show.legend = FALSE, size = 3) +
  theme(legend.position = "none", text = element_text(size = 6)) +
  ggtitle("Shuffled assignment of tire brand")

shuffbrandfull5 <- permdata %>%
    filter(car == "car  5") %>%
ggplot(aes( x = `Randomized Brand`, y = tread, color = `Randomized Brand`)) +
 # geom_boxplot() +
  geom_point() +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  xlab("Randomized brand of tire") +
  ylim(c(miny, maxy)) + 
  geom_text(aes(label = car), color = "grey",hjust = rep(c(-0.15,1.3), each = 1),
            show.legend = FALSE, size = 3) +
  ggtitle("Sorted data")

origplot5 + shuffbrand5 
```

We can put the shuffled assignments for all the cars into one plot as seen in Figure \@ref(fig:tiredataPerm).

```{r tiredataPerm, fig.cap = "Boxplots of the tire tread data (in cm) with: the brand of tire from which the original measurements came (left) and shuffled brand assignment (right).  As evidenced by the colors, some of the cars kept their original tire assignments and some cars swapped the tire assignments.", warning = FALSE, fig.asp = 0.50, fig.height = 10, out.width = "100%"}

theme_set(
  theme_bw() +
    theme(legend.position = "top", text = element_text(size = 6))
  )


origplot <- tires %>%
  mutate(`Tire Brand` = brand) %>%
ggplot(aes( x = `Tire Brand`, y = tread, color = `Tire Brand`)) +
 # geom_boxplot() +
  geom_text(aes(label = car), color = "grey",hjust = rep(c(-0.15, 1.3), each = 25),
            show.legend = FALSE, size = 2) +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  ylim(c(miny, maxy)) + 
  xlab("Brand of tire") +
  geom_point() +
  ggtitle("Original data")

shuffbrand <-permdata %>%
ggplot(aes( x = `Tire Brand`, y = tread, color = `Randomized Brand`)) +
 # geom_boxplot() +
  geom_point(show.legend = FALSE) +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  theme_void() +
  ylim(c(miny, maxy)) + 
  geom_text(aes(label = car), color = "grey",hjust = rep(c(-0.15, 1.3), each = 25),
            show.legend = FALSE, size = 2) +
  theme(legend.position = "none", text = element_text(size = 6)) +
  ggtitle("Shuffled assignment of tire brand")

permed_means <- permdata %>%
  group_by(`Randomized Brand`) %>%
  summarize(mean_tread = round(mean(tread),4))  %>%
  mutate(mean_label = c("bar(x)[QSsim1]", "bar(x)[STsim1]")) %>%
  mutate(mean_label = paste(mean_label, " == ", mean_tread))

shuffbrandfull <- permdata %>%
ggplot(aes( x = `Randomized Brand`, y = tread, color = `Randomized Brand`)) +
 # geom_boxplot() +
  geom_text(aes(label = car), color = "grey",hjust = rep(c(-0.15, 1.3), each = 25),
            show.legend = FALSE, size = 2) +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  xlab("Randomized brand of tire") +
  ylim(c(miny, maxy)) + 
  geom_point() +
  geom_text(data = permed_means, 
            aes(label = mean_label, 
                y = 0.318), parse = TRUE, show.legend = FALSE) + 
  ggtitle("Sorted data")

origplot + shuffbrand

```

The next step in the randomization test is to sort the brands so that the assigned brand value on the x-axis aligns with the assigned group from the randomization.
See Figure \@ref(fig:tiredataPermSort) which has the same randomized groups (right image in Figure \@ref(fig:tiredataPerm) and left image in Figure \@ref(fig:tiredataPermSort)) as seen previously.
However, the right image in Figure \@ref(fig:tiredataPermSort) sorts the randomized groups so that we can measure the variability across groups as compared to the variability within groups.

```{r tiredataPermSort, fig.cap = "Boxplots of the tire tread data (in cm) and (left) the brand of tire from which the original measurements came, (center) shuffled brand assignment, (right) sorted by randomized brand.", warning = FALSE, fig.asp = 0.50, out.width = "100%"}
shuffbrand + shuffbrandfull
```

Figure \@ref(fig:tiredatarand1) presents another randomization of the data.
Notice how the two observations from the same car are linked by a grey line; some of the tread values have been randomly assigned to the opposite tire brand than they were originally (while some are still connected to their original tire brands).

```{r tiredatarand1, fig.cap = "One randomization where the brand is randomly swapped (or not) across the two tread wear measurements (in cm) from the same car.", warning = FALSE, fig.asp = 0.50, out.width = "100%"}
# inches  about 1/32" per 3500 mi
set.seed(47)
tires1 <- tires %>%
  group_by(car) %>%
  mutate(`Randomized Tire Brand` = sample(brand))

permed_means <- tires1 %>%
  group_by(`Randomized Tire Brand`) %>%
  summarize(mean_tread = round(mean(tread),4))  %>%
  mutate(mean_label = c("bar(x)[QSsim2]", "bar(x)[STsim2]")) %>%
  mutate(mean_label = paste(mean_label, " == ", mean_tread))

ggplot(tires1, aes( x = `Randomized Tire Brand`, y = tread, color = `Randomized Tire Brand`)) +
  geom_boxplot(show.legend = FALSE,color = "black") +
  geom_point() +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  xlab("Brand of tires, randomly assigned (2).") +
    geom_text(data = permed_means, 
            aes(label = mean_label, 
                y = 0.318), parse = TRUE, show.legend = FALSE) 
```

Figure \@ref(fig:tiredatarand2) presents yet another randomization of the data.
Again, the same observations are linked by a grey line, and some of the tread values have been randomly assigned to the opposite tire brand than they were originally (while some are still connected to their original tire brands).

```{r tiredatarand2, fig.cap = "An additional randomization where the brand is randomly swapped (or not) across the two tread wear measurements (in cm) from the same car.", warning = FALSE, fig.asp = 0.50, out.width = "100%"}
# inches  about 1/32" per 3500 mi
set.seed(4747)
tires2 <- tires %>%
  group_by(car) %>%
  mutate(`Randomized Tire Brand` = sample(brand))

permed_means <- tires2 %>%
  group_by(`Randomized Tire Brand`) %>%
  summarize(mean_tread = round(mean(tread),4))  %>%
  mutate(mean_label = c("bar(x)[QSsim3]", "bar(x)[STsim3]")) %>%
  mutate(mean_label = paste(mean_label, " == ", mean_tread))

ggplot(tires2, aes( x = `Randomized Tire Brand`, y = tread, color = `Randomized Tire Brand`)) +
  geom_boxplot(show.legend = FALSE, color = "black") +
  geom_point() +
  geom_line(aes(group = car), color = "grey") +
  ylab("") + 
  xlab("Brand of tires, randomly assigned (3).") +
  geom_text(data = permed_means, 
            aes(label = mean_label, 
                y = 0.318), parse = TRUE, show.legend = FALSE)
```

### Observed statistic vs. null statistics {.unnumbered}

By repeating the randomization process, we can create a distribution of the average of the differences in tire treads, as seen in Figure \@ref(fig:pairRandomiz).
As expected (because the differences were generated under the null hypothesis), the center of the histogram is zero.
A line has been drawn at the observed difference which is nowhere near the differences simulated from natural variability by mixing up which the tire received Smooth Turn and which received Quick Spin.
Because the observed statistic is so far away from the natural variability of the randomized differences, we believe that there is a significant difference between Smooth Turn and Quick Spin.
Our conclusion is that the extra amount of average tire tread in Smooth Turn is due to more than just natural variability: we reject $H_0$ and conclude that $\mu_{ST} > \mu_{QS}.$

```{r pairrandfull, fig.cap = "process of randomizing across pairs.", warning = FALSE,  out.width="75%", eval = FALSE, echo = FALSE}
include_graphics("images/pairrandfull.png")
```

```{r pairRandomiz, fig.cap = "Histogram of 1000 differences with tire brand randomly assigned across the two observations (in cm) per pair.", warning = FALSE, fig.width=10}
# inches  about 1/32" per 3500 mi

obs_diff <- mean(brandA) - mean(brandB)

set.seed(4747)
diffRand <- c()
for (i in 1:1000){

tirediff <- data.frame(brandA, brandB) %>%
  mutate(diffs = brandA - brandB) %>%
  mutate(grpPerm = sample(c(-1,1), 25, replace = TRUE)) %>%
  mutate(diffsPerm = diffs * grpPerm) %>%
  summarize(mean(diffsPerm)) %>% pull()

diffRand <- c(diffRand, tirediff)
}
  
diff.df = data.frame(diffRand)
  
ggplot(diff.df, aes( x = diffRand)) +
  geom_histogram() +
  ylab("") + 
  xlab("Difference in tire wear, across randomly assigned groups.") +
  ggtitle("Difference in wear of tire tread (in inches) after 1,000 miles,\n brand randomly assigned.") + 
  geom_vline(xintercept = obs_diff, color = "#F05133") 
```

## Bootstrap confidence interval for $\mu_d$

For both the bootstrap and the mathematical models applied to paired data, the analysis is virtually identical to the one-sample approach given in Section \@ref(inference-one-mean).
The key to working with paired data (for bootstrapping and mathematical approaches) is to consider the measurement of interest to be the difference in measured values across the pair of observations.

### Observed data {.unnumbered}

In an earlier edition of this textbook, we found that Amazon prices were, on average, lower than those of the UCLA Bookstore for UCLA courses in 2010.
It's been several years, and many stores have adapted to the online market, so we wondered, how is the UCLA Bookstore doing today?

We sampled 201 UCLA courses.
Of those, 68 required books could be found on Amazon.
A portion of the data set from these courses is shown in Figure \@ref(tab:textbooksDF), where prices are in US dollars.

```{r textbooksDF}
data("ucla_textbooks_f18")

ucla_textbooks_f18 %>% 
  select(subject, course_num, bookstore_new, amazon_new) %>%
  mutate(price_diff = bookstore_new - amazon_new) %>%
  filter(!is.na(bookstore_new) & !is.na(amazon_new)) %>%
  head(4) %>%
   kable(caption = "Four cases of the `ucla_textbooks_f18` dataset.") %>%
 kable_styling() 

```

\index{paired|(} \index{data!textbooks|(}

Each textbook has two corresponding prices in the data set: one for the UCLA Bookstore and one for Amazon.
When two sets of observations have this special correspondence, they are said to be **paired**.

### Variability of the statistic {.unnumbered}

Following the example of bootstrapping the one-sample statistic, the observed *differences* can be bootstrapped in order to understand the variability of the average difference from sample to sample.
Remember, the differences act as a single value to bootstrap.
That is, the original dataset would include the list of 68 price differences, and each resample will also include 68 price differences (some repeated through the bootstrap resampling process).
The bootstrap procedure for paired differences is quite similar to the procedure applied to the one-sample statistic case in Section \@ref(boot1mean).

In Figure \@ref(fig:pairboot), two 99% confidence intervals for the difference in the cost of a new book at the UCLA bookstore compared with Amazon have been calculated.
The bootstrap percentile confidence interval is computing using the 0.5 percentile and 99.5 percentile bootstrapped differences and is found to be (\$0.25, \$7.87).
The bootstrap SE interval is found by computing the SE of the bootstrapped differences $(SE_{\overline{x}_{diff}} = \$1.64)$ and the normal multiplier of $z^* = 2.58.$ The averaged difference is $\bar{x} = \$3.58.$ The 99% confidence interval is: $\$3.58 \pm 2.58 \cdot \$ 1.64 \rightarrow (\$-0.65, \$7.81).$ The confidence intervals seem to indicate that the UCLA bookstore price is, on average, higher than the Amazon price.
However, if the analysis required a strong degree of certainty (e.g., 99% confidence), and the bootstrap SE interval was most appropriate (given a second course in statistics the nuances of the methods were investigated), the results of which book seller is higher is not well determined.
That is, the 99% bootstrap SE interval gives potential for UCLA to be lower, on average, than Amazon (because of the possible negative values for the true mean difference in price).

```{r pairboot, fig.cap = "Bootstrap distribution for the average difference in new book price at the UCLA bookstore versus Amazon.  99% confidence intervals are superimposed using blue (bootstrap percentile interval) and green (bootstrap SE interval) lines.", warning = FALSE, fig.width=10}
# inches  about 1/32" per 3500 mi

diff_price <- ucla_textbooks_f18 %>% 
  select(subject, course_num, bookstore_new, amazon_new) %>%
  mutate(price_diff = bookstore_new - amazon_new) %>%
  filter(!is.na(bookstore_new) & !is.na(amazon_new)) %>%
  specify(response = price_diff) %>%
  calculate(stat = "mean")

boot_diff <- ucla_textbooks_f18 %>% 
  select(subject, course_num, bookstore_new, amazon_new) %>%
  mutate(price_diff = bookstore_new - amazon_new) %>%
  filter(!is.na(bookstore_new) & !is.na(amazon_new)) %>%
  specify(response = price_diff) %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "mean") 

ci_perc_diff <- boot_diff %>%
  get_confidence_interval(level = 0.99, type = "percentile")

ci_se_diff <- boot_diff %>%
  get_confidence_interval(level = 0.99, type = "se",
                          point_estimate = diff_price)
boot_diff %>%
  infer::visualize(bins = 20) +
  infer::shade_confidence_interval(ci_perc_diff, 
                                   color = "#569BBD", 
                                   fill = NULL, size = .5) +
  infer::shade_confidence_interval(ci_se_diff, 
                                   color = "#4C721D",
                                   fill = NULL, size = .5) +
  ggtitle("Simulation-Based Bootstrap Distribution for Mean Difference") +
  geom_vline(xintercept = diff_price$stat) +  
  geom_line(aes(y = replicate, x = stat, color = "a"), alpha = 0) +  # bogus code
  geom_line(aes(y = replicate, x = stat, color = "b"), alpha = 0) +  # bogus code
  geom_line(aes(y = replicate, x = stat, color = "c"), alpha = 0) +  # bogus code
  ylim(c(0,200)) + 
  guides(color = guide_legend(override.aes = list(alpha = 1))) +
  scale_color_manual(name = "CI type",
                       values = c("a" = "#569BBD", "b" = "#4C721D", "c" = "#000000"),
                       labels = c("Percentile", "SE", "Observed stat"),
                     guide = "legend")

#ci_perc_diff
#ci_se_diff

```

## Mathematical model {#mathparied}

Thinking about the differences as a single observation on an observational unit changes the paired setting into the one-sample setting.
The mathematical model for the one-sample case is covered in Section \@ref(one-mean-math).

### Observed data {.unnumbered}

To analyze paired data, it is often useful to look at the difference in outcomes of each pair of observations.
In the textbook data, we look at the differences in prices, which is represented as the `price_difference` variable in the data set.
Here the differences are taken as

$$ \text{UCLA Bookstore price} - \text{Amazon price} $$

It is important that we always subtract using a consistent order; here Amazon prices are always subtracted from UCLA prices.
The first difference shown in Table \@ref(tab:textbooksDF) is computed as $47.97 - 47.45 = 0.52.$ Similarly, the second difference is computed as $14.26 - 13.55 = 0.71,$ and the third is $13.50 - 12.53 = 0.97.$ A histogram of the differences is shown in Figure \@ref(fig:diffInTextbookPricesF18).
Using differences between paired observations is a common and useful way to analyze paired data.

```{r diffInTextbookPricesF18, fig.cap = "Histogram of the difference in price for each book sampled.", warning = FALSE, fig.width = 10}

data("ucla_textbooks_f18")

d <- ucla_textbooks_f18 %>% 
  select(subject, course_num, bookstore_new, amazon_new) %>%
  mutate(price_diff = bookstore_new - amazon_new) %>%
  filter(!is.na(bookstore_new) & !is.na(amazon_new))

histPlot(d$price_diff, axes = FALSE, # breaks = 20,
         xlab = "UCLA Bookstore Price - Amazon Price (USD)",
         ylab = "",
         col = COL[1])
AxisInDollars(1, at = pretty(d$price_diff), tck = -0.03)
axis(2, at = seq(0, 30, 10), tck = -0.02)
# axis(2, at = seq(0, 15, 5), tck = -0.02)
par(las = 0)
mtext("Frequency", 2, 2.4)
```

### Variability of the statistic {.unnumbered}

To analyze a paired data set, we simply analyze the differences.
Table \@ref(tab:textbooksSummaryStats) provides the data summaries from the textbook data.
Note that instead of reporting the prices separately for UCLA and Amazon, the summary statistics are given by the mean of the differences, the standard deviation of the differences, and the total number of pairs (i.e., differences).
The parameter of interest is also a single value, $\mu_{diff},$ so we can use the same $t$-distribution techniques we applied in Section \@ref(one-mean-math) directly onto the observed differences.

```{r textbooksSummaryStats}
temptbl <- tribble(
  ~col0,    ~col1, ~col2,
  68, 3.58, 13.42
)

temptbl %>%
 kable(caption = "Summary statistics for the 68 price differences.",
    col.names = c("$n_{diff}$", "$\\bar{x}_{diff}$", "$s_{diff}$")) %>%
 kable_styling() 
```

::: {.workedexample}
Set up a hypothesis test to determine whether, on average, there is a difference between Amazon's price for a book and the UCLA bookstore's price.
Also, check the conditions for whether we can move forward with the test using the $t$-distribution.

------------------------------------------------------------------------

We are considering two scenarios: there is no difference or there is some difference in average prices.

-   $H_0:$ $\mu_{diff} = 0.$ There is no difference in the average textbook price.

-   $H_A:$ $\mu_{diff} \neq 0.$ There is a difference in average prices.

    Next, we check the independence and normality conditions.
    The observations are based on a simple random sample, so independence is reasonable.
    While there are some outliers, $n = 68$ and none of the outliers are particularly extreme, so the normality of $\bar{x}$ is satisfied.
    With these conditions satisfied, we can move forward with the $t$-distribution.
:::

### Observed statistic vs. null statistics {.unnumbered}

As mentioned previously, the methods applied to a difference will be identical to the one-sample techniques.
Therefore, the full hypothesis test framework is presented as guided practices.

::: {.important}
**The test statistic for assessing a paired mean is a T.**

The T score is a ratio of how the sample mean difference varies from zero as compared to how the observations vary.

$$ T = \frac{\bar{x}_{diff}}{s_{diff}/\sqrt{n_{diff}}} $$

When the null hypothesis is true and the conditions are met, T has a t-distribution with $df = n_{diff} - 1.$

Conditions:

-   independently observed pairs\
-   large samples and no extreme outliers\
:::

::: {.guidedpractice}
Complete the hypothesis test started in the previous Example.[^inference-paired-means-1]
:::

[^inference-paired-means-1]: To compute the test compute the standard error associated with $\bar{x}_{diff}$ using the standard deviation of the differences $(s_{diff} = 13.42)$ and the number of differences $(n_{diff} = 68):$

$$
SE_{\bar{x}_{diff}} &= \frac{s_{diff}}{\sqrt{n_{diff}}} = \frac{13.42}{\sqrt{68}} = 1.63
$$

The test statistic is the T-score of $\bar{x}_{diff}$ under the null condition that the actual mean difference is 0:

$$
T = \frac{\bar{x}_{diff} - 0}{SE_{x_{diff}}} = \frac{3.58 - 0}{1.63} = 2.20
$$

To visualize the p-value, the sampling distribution of $\bar{x}_{diff}$ is drawn as though $H_0$ is true, and the p-value is represented by the two shaded tails in Figure \@ref(fig:textbooksF18HTTails).\
The degrees of freedom is $df = 68 - 1 = 67.$ Using statistical software, we find the one-tail area of 0.0156.
Doubling this area gives the p-value: 0.0312.\
Because the p-value is less than 0.05, we reject the null hypothesis
. Amazon prices are, on average, lower than the UCLA Bookstore prices for UCLA courses
.

```{r textbooksF18HTTails, fig.cap = "Distribution of $\\bar{x}_{diff}$ under the null hypothesis of no difference.  The observed average difference of 2.98 is marked with the shaded areas more extreme than the observed difference given as the p-value.", warning = FALSE, echo = FALSE}

m <- mean(d$price_diff)
s <- sd(d$price_diff)
se <- s / sqrt(length(d$price_diff))
z <- m / se

normTail(L = -abs(m),
         U = abs(m),
         s = se,
         df = 20,
         # xlim = 5 * c(-1, 1),
         col = COL[1],
         # border = COL[4],
         axes = FALSE)
at <- c(-100, 0, m, 100)
labels <- expression(0, mu[0]*' = 0', bar(x)[diff]*" = 2.98", 0)
axis(1, at, labels, cex.axis = 0.9)

```

::: {.guidedpractice}
Create a 95% confidence interval for the average price difference between books at the UCLA bookstore and books on Amazon.[^inference-paired-means-2]
:::

[^inference-paired-means-2]: Conditions have already verified and the standard error computed in a previous Example.\
    To find the confidence interval, identify $t^{\star}_{67}$ using statistical software or the $t$-table $(t^{\star}_{67} = 2.00),$ and plug it, the point estimate, and the standard error into the confidence interval formula:

$$
\text{point estimate} \ &\pm \ z^{\star} \times SE \\
3.58 \ &\pm \ 2.00 \times 1.63 \\
(0.32 \ &, \ 6.84)
$$

We are 95% confident that Amazon is, on average, between \$0.32 and \$6.84 less expensive than the UCLA Bookstore for UCLA course books.

::: {.guidedpractice}
We have strong evidence that Amazon is, on average, less expensive.
How should this conclusion affect UCLA student buying habits?
Should UCLA students always buy their books on Amazon?[^inference-paired-means-3]
:::

[^inference-paired-means-3]: The average price difference is only mildly useful for this question.
    Examine the distribution shown in Figure \@ref(fig:diffInTextbookPricesF18).
    There are certainly a handful of cases where Amazon prices are far below the UCLA Bookstore's, which suggests it is worth checking Amazon (and probably other online sites) before purchasing.
    However, in many cases the Amazon price is above what the UCLA Bookstore charges, and most of the time the price isn't that different.
    Ultimately, if getting a book immediately from the bookstore is notably more convenient, e.g. to get started on reading or homework, it's likely a good idea to go with the UCLA Bookstore unless the price difference on a specific book happens to be quite large.
    For reference, this is a very different result from what we (the authors) had seen in a similar data set from 2010.
    At that time, Amazon prices were almost uniformly lower than those of the UCLA Bookstore's and by a large margin, making the case to use Amazon over the UCLA Bookstore quite compelling at that time.
    Now we frequently check multiple websites to find the best price.

\index{paired}

## t-procedures

So far in this chapter, we have seen the $t$-distribution applied as the appropriate mathematical model in three distinct settings.
Although the three data structures are different, their similarities and differences are worth pointing out.
We provide Table \@ref(tab:tcompare) partly as a mechanism for understanding $t$-procedures and partly to highlight the extremely common usage of the $t$-distribution in practice.

```{r tcompare}
tsim_table <- tribble(
  ~variable,    ~col1, ~col2, ~col3,
"response variable",  "numeric", "numeric",  "numeric",

"parameter of interest", "mean: $\\mu$", "paired mean: $\\mu_{diff}$",  "diff in means: $\\mu_1 - \\mu_2$",


"statistic of interest", "mean: $\\bar{x}$", "paired mean: $\\bar{x}_{diff}$",  "diff in means: $\\bar{x}_1 - \\bar{x}_2$",

"standard error", "$\\frac{s}{\\sqrt{n}}$", "$\\frac{s_{diff}}{\\sqrt{n_{diff}}}$", "$\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}$",

"degrees of freedom", "$n-1$", "$n_{diff} -1$", "$\\min(n_1 -1, n_2 - 1)$",

"conditions", "1. independence, 2. normality or large samples", "1. independence, 2. normality or large samples", "1. independence, 2. normality or large samples"
)

tsim_table %>%
 kable(caption = "Similarities of $t$-methods across one sample, paired sample, and two independent samples analysis of a numeric response variable.", 
    col.names = c("", " one sample ", "paired sample", "two indep. samples")) %>%
 kable_styling()
```

**Hypothesis tests.** When applying the $t$-distribution for a hypothesis test, we proceed as follows:

-   Write appropriate hypotheses.

-   Verify conditions for using the $t$-distribution.

    -   One-sample or differences from paired data: the observations (or differences) must be independent and nearly normal. For larger sample sizes, we can relax the nearly normal requirement, e.g., slight skew is okay for sample sizes of 15, moderate skew for sample sizes of 30, and strong skew for sample sizes of 60.\
    -   For a difference of means when the data are not paired: each sample mean must separately satisfy the one-sample conditions for the $t$-distribution, and the data in the groups must also be independent.

-   Compute the point estimate of interest, the standard error, and the degrees of freedom For $df,$ use $n-1$ for one sample, and for two samples use either statistical software or the smaller of $n_1 - 1$ and $n_2 - 1.$\

-   Compute the T-score and p-value.

-   Make a conclusion based on the p-value, and write a conclusion in context and in plain language so anyone can understand the result.

**Confidence intervals.** Similarly, the following is how we generally computed a confidence interval using a $t$-distribution:

-   Verify conditions for using the $t$-distribution. (See above.)\
-   Compute the point estimate of interest, the standard error, the degrees of freedom, and $t^{\star}_{df}.$\
-   Calculate the confidence interval using the general formula, point estimate $\pm\ t_{df}^{\star} SE.$\
-   Put the conclusions in context and in plain language so even non-data scientists can understand the results.

## Chapter review {#chp21-review}

### Summary

::: {.todo}
Add summary
:::

### Terms

We introduced the following terms in the chapter.
If you're not sure what some of these terms mean, we recommend you go back in the text and review their definitions.

```{r eval=FALSE}
make_terms_table(terms_chp_21)
```

## Exercises

::: {.todo}
Add exercieses
:::
