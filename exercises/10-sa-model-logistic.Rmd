1. \(a) There are a few potential outliers, e.g. on the left in the variable, but nothing that will be of serious concern in a data set this large. (b) When coefficient estimates are sensitive to which variables are included in the model, this typically indicates that some variables are collinear. For example, a possum's gender may be related to its head length, which would explain why the coefficient (and p-value) changed when we removed the variable. Likewise, a possum's skull width is likely to be related to its head length, probably even much more closely related than the head length was to gender.

1. \(a) The logistic model relating $\hat{p}_i$ to the predictors may be written as $\log\left( \frac{\hat{p}_i}{1 - \hat{p}_i} \right) = 33.5095 - 1.4207\times sex\_male_i - 0.2787 \times skull\_width_i  + 0.5687 \times total\_length_i - 1.8057 \times tail\_length_i$. Only has a positive association with a possum being from Victoria. (b) $\hat{p} = 0.0062$. While the probability is very near zero, we have not run diagnostics on the model. We might also be a little skeptical that the model will remain accurate for a possum found in a US zoo. For example, perhaps the zoo selected a possum with specific characteristics but only looked in one region. On the other hand, it is encouraging that the possum was caught in the wild. (Answers regarding the reliability of the model probability will vary.)

1. \(a)False. The log-odds will change the same amount, but these changes are not generally proportional to a change in probability. (b) True. (c) False. Independent observations is a condition for applying standard logistic regression methods. More advanced methods are needed when observations are not independent. (d) False. We typically use AIC.

1. \(a)The equation is: $\log\left(\frac{p_i}{1 - p_i}\right) = -0.8124 - 2.6351 \times \texttt{to_multiple} + 1.6272 \times \texttt{winner}- 1.5881 \times \texttt{format} - 3.0467 \times \texttt{re_subj}$. (b) First find $\log\left(\frac{p}{1 - p}\right)$, then solve for $p$: $\log\left(\frac{p}{1 - p}\right) = -0.8124 - 2.6351 \times 0 + 1.6272 \times 1 - 1.5881 \times 0 - 3.0467 \times 0 = 0.8148 \rightarrow \frac{p}{1 - p} = e^{0.8148} \rightarrow p = 0.693$ (c) It should probably be pretty high, since it could be very disruptive to the person using the email service if they are missing emails that aren't spam. Even only a 90% chance that a message is spam is probably enough to warrant keeping it in the inbox. Maybe a probability of 99% would be a reasonable cutoff. As for other ideas to make it even better, it may be worth building a second model that tries to classify the importance of an email message. If we have both the spam model and the importance model, we now have a better way to think about cost-benefit tradeoffs. For instance, perhaps we would be willing to have a lower probability-of-spam threshold for messages we were confident were not important, and perhaps we want an even higher probability threshold (e.g. 99.99%) for emails we are pretty sure are important.
